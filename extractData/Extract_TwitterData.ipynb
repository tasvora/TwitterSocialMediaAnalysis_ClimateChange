{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect tweets related to Climate Change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "#### Step 1 - Used ***Used GetOldTweets3*** A python 3 library to extract tweets for ***year of 2019***\n",
    "\n",
    "#### Step2 - Saved the extracted tweets in a comma seperated file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GetOldTweets3 as got\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Reviewed a list of climate related hashtags and picked 13 hashtags to fetch tweets.\n",
    "- Location was an option used to collect tweets, from a specific location. \n",
    "- Execute program per location manually.\n",
    "\n",
    "_next step would be to optimize it and run for a list of places_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_hashtags = ['#climateStrike','#climatestrike','#climatechange','#GreenNewDeal','#climatecrisis','#climateAction',\n",
    "                   '#FridaysForFuture','#environment','#globalwarming','#GlobalWarming','#ActOnClimate',\n",
    "                   '#sustainability','#savetheplanet','#bushfiresAustralia','#bushfires']\n",
    "# locations = { 'Newyork': 'USA', 'Chicago': 'USA' }\n",
    "\n",
    "locationcity = 'NewYork'\n",
    "locationcountry = 'USA'\n",
    "nearLocation = locationcity +\", \"+locationcountry\n",
    "\n",
    "year = '2018'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#climateStrike\n",
      "#climatestrike\n",
      "#climatechange\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tasne\\envs\\newproject\\lib\\site-packages\\pandas\\core\\frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#GreenNewDeal\n",
      "#climatecrisis\n",
      "#climateAction\n",
      "#FridaysForFuture\n",
      "#environment\n",
      "#globalwarming\n",
      "#GlobalWarming\n",
      "#ActOnClimate\n",
      "#sustainability\n",
      "#savetheplanet\n",
      "#bushfiresAustralia\n",
      "#bushfires\n"
     ]
    }
   ],
   "source": [
    "## scrape data from twitter for the above search terms\n",
    "\n",
    "tweet_df_all = pd.DataFrame()\n",
    "# for city, country in locations.items(): \n",
    "#     location = city+\", \"+ country\n",
    "#     print(f'fetching tweets for location {location}')\n",
    "#     fileName = city\n",
    "    \n",
    "for term in search_hashtags:\n",
    "    print(term)\n",
    "    tweetCriteria = got.manager.TweetCriteria().setQuerySearch(term)\\\n",
    "                                               .setSince(\"2019-01-01\")\\\n",
    "                                               .setUntil(\"2019-02-01\")\\\n",
    "                                               .setNear(nearLocation)\\\n",
    "                                               .setWithin(\"350mi\")\n",
    "    tweet = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "\n",
    "    tweet_list = [[tweet[x].id,\n",
    "                  tweet[x].author_id,\n",
    "                  tweet[x].text,\n",
    "                  tweet[x].retweets,\n",
    "                  tweet[x].permalink,\n",
    "                  tweet[x].date,\n",
    "                  tweet[x].formatted_date,\n",
    "                  tweet[x].favorites,\n",
    "                  tweet[x].mentions,\n",
    "                  tweet[x].hashtags,\n",
    "                  tweet[x].geo,\n",
    "                  tweet[x].urls\n",
    "                 ]for x in range(0, len(tweet))]\n",
    "    tweet_df = pd.DataFrame(tweet_list)\n",
    "    tweet_df['search_hashtags'] = term\n",
    "    tweet_df['location'] = nearLocation\n",
    "    tweet_df_all = tweet_df_all.append(tweet_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "tweet_df_all.columns = ['id','author_id','text','retweets','permalink','date','formatted_date','favorites','mentions','hashtags','geo','urls','search_term','location']\n",
    "#tweet_df_all = tweet_df_all[tweet_df_all['text'].notna()]\n",
    "saveFileLocation = \"../data/TwitterData/\"+year+\"/all_tweets_\"+nearLocation+\"_\"+year+\".csv\"\n",
    "tweet_df_all.to_csv(saveFileLocation, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
