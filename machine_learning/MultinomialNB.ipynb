{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB as MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df_location = pd.read_csv('../data/graphAnalysis/clean_climateTwitterData.csv')\n",
    "tweet_df_location = tweet_df_location[tweet_df_location['text'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "# This step was performed in the sentiment Analyzer\n",
    "# def replace_urls(in_string, replacement=None):\n",
    "#     # \"\"\"Replace URLs in strings. See also: ``bit.ly/PyURLre``\n",
    "\n",
    "#     # Args:\n",
    "#     #     in_string (str): string to filter\n",
    "#     #     replacement (str or None): replacment text. defaults to '<-URL->'\n",
    "\n",
    "#     # Returns:\n",
    "#     #     str\n",
    "#     # \"\"\"\n",
    "#     replacement = '<-URL->' if replacement is None else replacement\n",
    "#     pattern = re.compile('(https?://)?(\\w*[.]\\w+)+([/?=&]+\\w+)*')\n",
    "#     return re.sub(pattern, replacement, in_string)\n",
    "\n",
    "\n",
    "def tokenize_only(in_string):\n",
    "    \"\"\"\n",
    "    Convert `in_string` of text to a list of tokens using NLTK's TweetTokenizer\n",
    "    \"\"\"\n",
    "    # reasonable, but adjustable tokenizer settings\n",
    "    tokenizer = TweetTokenizer(preserve_case=False,\n",
    "                               reduce_len=True,\n",
    "                               strip_handles=False)\n",
    "    tokens = tokenizer.tokenize(in_string)\n",
    "    return tokens\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step was performed in the sentiment Analyzer\n",
    "# # remove urls and retweets and entities from the text\n",
    "# tweet_df_location['text_clean'] = tweet_df_location['text'].apply(lambda row:replace_urls(row))\n",
    "\n",
    "# #remove punctuations\n",
    "# RE_PUNCTUATION = '|'.join([re.escape(x) for x in string.punctuation])  \n",
    "# tweet_df_location['text_clean'] = tweet_df_location['text_clean'].str.replace(RE_PUNCTUATION, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' did', \" i'm\", \" who'd\", ' been', 'them', 'being', \"haven't\", 'd', \" doesn't\", ' do', 'your', 'hasn', 'you', 'ought', \" they're\", 'weren', ' and', 'her', ' my', \"you're\", 's', ' does', ' any', 'shouldn', \"they're\", ' twas', ' you', \"isn't\", ' am', 'wouldn', \" you're\", \"she'd\", 'doesn', 'into', \" that's\", ' which', 'yourself', ' most', 'has', 'didn', \" there's\", \" mustn't\", \"wouldn't\", 'i', 'an', 'm', ' on', 'this', 'these', 'some', \" he'll\", 'down', ' with', '#climatestrike', 'doing', \"we'd\", \" he's\", 'if', \" you'll\", 'because', 'did', 'myself', \" mightn't\", ' says', ' often', '#climateAction', ' then', 'again', \"that's\", \" won't\", \" don't\", \" shan't\", ' because', 'then', \"mightn't\", ' will', \"won't\", \" she's\", \" where'll\", ' own', 'under', 'out', ' this', 'nor', \"don't\", \" would've\", \" what'd\", \"how's\", \"where's\", \" how's\", ' across', ' who', ' of', '#climatechange', ' like', ' after', ' in', ' if', ' however', \" ain't\", 'between', 'and', ' likely', \" didn't\", ' wants', \"couldn't\", 'further', \" he'd\", 'had', ' other', 'his', ' might', 't', \"they'll\", 'below', 'each', 'until', \"we're\", ' get', 'http', '#sustainability', 'such', 'are', 'who', 'my', \" why's\", ' not', \" aren't\", ' so', ' why', \" wouldn't\", 'it', ' can', 'just', ' into', 'would', 'wasn', ' say', \" they've\", 'won', 'a', ' tis', 'aren', 'at', 'him', ' almost', \" where'd\", ' she', \"she'll\", 'me', ' else', ' or', \" who'll\", \" we'll\", \"we've\", 'ourselves', \" should've\", 'those', ' the', 'other', 'against', 'about', 'after', \" how'll\", ' from', ' for', ' at', \" how'd\", \"hadn't\", 'while', ' either', 'why', ' cannot', \" hasn't\", 'by', ' a', \"shan't\", 'own', 'mustn', \" wasn't\", 'she', 'they', 'whom', \" they'll\", ' since', ' able', ' than', 'any', ' where', 'is', 'our', 'o', \"you've\", \"who's\", \" when'd\", 'from', 'have', ' it', \"let's\", ' while', 'hers', 'he', \"shouldn't\", \" you'd\", 'before', 'what', 'that', 'or', ' to', \" can't\", \"'tis\", ' him', ' your', \"he'll\", ' no', \"wasn't\", ' me', 'y', ' only', 'here', ' us', ' every', \" why'd\", ' his', ' their', ' by', 'ain', ' has', 'https', 'having', ' whom', '#ActOnClimate', 'yourselves', 'there', 'few', 'does', ' got', ' hers', ' rather', \" isn't\", \"he'd\", 'so', \"he's\", ' should', \" could've\", \" i'll\", ' must', \"when's\", \"didn't\", '#environment', 'its', 'on', \" i'd\", ' is', ' there', 'most', \"we'll\", ' was', 'now', 'don', \" what's\", ' he', 'in', 'both', 'himself', \"i'm\", ' would', ' we', \" might've\", ' its', \"what's\", 'only', ' were', 'up', 'all', \" couldn't\", \"i'll\", 'was', ' also', \" why'll\", ' them', \" she'll\", ' but', \"aren't\", \" she'd\", 'above', \" we'd\", \"here's\", '#GreenNewDeal', \"doesn't\", \"why's\", 'once', 'their', 'we', 'ma', ' had', ' some', \"she's\", '#globalwarming', 'couldn', ' too', ' our', \"hasn't\", ' they', \"should've\", ' all', 've', 'am', 'be', 'through', \"they'd\", ' what', ' as', '#GlobalWarming', 'same', 'which', 'themselves', 'no', ' how', 'theirs', ' could', 'should', \" must've\", 'more', \" they'd\", 'very', \"mustn't\", \"there's\", 'but', 'when', ' her', ' be', \" we're\", ' are', \"weren't\", \"that'll\", 'where', 'the', 'not', ' that', 'itself', \" when'll\", ' dear', ' about', 'too', ' said', \" where's\", ' neither', \" shouldn't\", \"you'd\", 'll', 'needn', 'do', \" who's\", ' an', \" when's\", 'haven', ' i', ' these', 'could', \" weren't\", 'as', 'shan', 'been', 'mightn', 'yours', \"it's\", 'isn', '#bushfires', '#climateStrike', 'for', ' nor', \" you've\", 'can', ' just', \"they've\", ' when', \" that'll\", 'during', 'than', 'herself', ' yet', 'over', '#FridaysForFuture', 'were', ' may', \" it's\", ' have', ' least', \"you'll\", \"needn't\", ' off', 're', \"i've\", 'will', ' let', '#bushfiresAustralia', '#savetheplanet', 'of', ' ever', 'to', 'with', 'hadn', \" i've\", 'ours', \" 'twas\", \"i'd\", 'how', 'off', ' among', '#climatecrisis']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# List of stopwords\n",
    "stop_words= stopwords.words('english') #import stopwords from NLTK package\n",
    "readInStopwords = pd.read_csv(\"pre_process/twitterStopWords.csv\", encoding='ISO-8859-1') # import stopwords from CSV file as pandas data frame\n",
    "readInStopwords = readInStopwords.wordList.tolist() # convert pandas data frame to a list\n",
    "readInStopwords.append('http')\n",
    "readInStopwords.append('https')\n",
    "\n",
    "search_terms = ['#climateStrike','#climatestrike','#climatechange','#GreenNewDeal','#climatecrisis','#climateAction','#FridaysForFuture',\n",
    "            '#environment','#globalwarming','#GlobalWarming','#ActOnClimate','#sustainability','#savetheplanet',\n",
    "        '#bushfiresAustralia','#bushfires']\n",
    "readInStopwords.extend(search_terms)\n",
    "stop_list = stop_words + readInStopwords # combine two lists i.e. NLTK stop words and CSV stopwords\n",
    "stop_list = list(set(stop_list)) # strore only unique values \n",
    "    \n",
    "print(stop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tweet_df_location['text_clean']\n",
    "y = tweet_df_location['search_hashtags']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tasne\\envs\\newproject\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['#actonclimate', '#bushfiresaustralia', '#climateaction', '#fridaysforfuture', '#greennewdeal', \"'\", 'able', 'across', \"ain't\", 'almost', 'also', 'among', \"can't\", 'cannot', \"could've\", 'dear', 'either', 'else', 'ever', 'every', 'get', 'got', \"how'd\", \"how'll\", 'however', 'least', 'let', 'like', 'likely', 'may', 'might', \"might've\", 'must', \"must've\", 'neither', 'often', 'rather', 'said', 'say', 'says', 'since', 'tis', 'twas', 'us', 'wants', \"what'd\", \"when'd\", \"when'll\", \"where'd\", \"where'll\", \"who'd\", \"who'll\", \"why'd\", \"why'll\", \"would've\", 'yet'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf_vectorizer = TfidfVectorizer(max_df=0.9, min_df=0.00, stop_words=stop_list, tokenizer=tokenize_only) # Use tf (raw term count) features for LDA.\n",
    "X_Vect = tf_vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_Vect, y, test_size=0.30, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50683, 87818)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50683,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21722, 87818)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21722,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   8    0    0  306    2  247    0    0    0    5    0    0]\n",
      " [   0    0    0  253    0   17    0    0    0    0    0    0]\n",
      " [   0    0  118  946    2  829    5    0    6    1    0    6]\n",
      " [   0    0    7 3913    2  898   15    0    6    6    0   10]\n",
      " [   0    0    7 1020   49  411    3    0    1    3    0    1]\n",
      " [   0    0    4  331    0 5162    4    2    0    0    0    4]\n",
      " [   0    0    0  916    0  236  220    0    4    0    0   35]\n",
      " [   0    0   10   83    0  772   12   33    0    0    0    1]\n",
      " [   0    0    0  888    1  164   22    0  170    0    0    1]\n",
      " [   0    0    0  730    0  404    0    0    0  243    0    0]\n",
      " [   0    0    0  224    0  153   16    0    8    0   15   14]\n",
      " [   0    0    2  967    0  188   15    0   11    0    0  554]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tasne\\envs\\newproject\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    #actonclimate       1.00      0.01      0.03       568\n",
      "       #bushfires       0.00      0.00      0.00       270\n",
      "   #climateaction       0.80      0.06      0.11      1913\n",
      "   #climatechange       0.37      0.81      0.51      4857\n",
      "   #climatecrisis       0.88      0.03      0.06      1495\n",
      "   #climatestrike       0.54      0.94      0.69      5507\n",
      "     #environment       0.71      0.16      0.26      1411\n",
      "#fridaysforfuture       0.94      0.04      0.07       911\n",
      "   #globalwarming       0.83      0.14      0.23      1246\n",
      "    #greennewdeal       0.94      0.18      0.30      1377\n",
      "   #savetheplanet       1.00      0.03      0.07       430\n",
      "  #sustainability       0.88      0.32      0.47      1737\n",
      "\n",
      "         accuracy                           0.48     21722\n",
      "        macro avg       0.74      0.23      0.23     21722\n",
      "     weighted avg       0.66      0.48      0.39     21722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48269036000368293"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy is -- 0.4743117576650401 without Tokenization and Stopwords\n",
    "- Accuracy is -- 0.4820458521314796 with Tokenization and Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 87818)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strVal = [\"Cuyahoga county eliminates use of plastic bags\",\"Weather is still warm in winters and is not freezing\"]\n",
    "Value = tf_vectorizer.transform(strVal)\n",
    "Value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['#environment', '#climatechange'], dtype='<U17')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.predict(Value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.61\n",
      "Best parameters:  {'alpha': 0.01}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'alpha': [0.001, 0.01, 0.1, 1]}\n",
    "\n",
    "grid = GridSearchCV(MNB(), param_grid, cv=10)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Best parameters: \", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Best cross-validation score: 0.61\n",
    "- Best parameters:  {'alpha': 0.01}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['#environment', '#globalwarming'], dtype='<U17')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.predict(Value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
