{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression as LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df_location = pd.read_csv('../data/graphAnalysis/clean_climateTwitterData.csv')\n",
    "tweet_df_location = tweet_df_location[tweet_df_location['text'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "#This step is done in Sentiment Analyzer\n",
    "# def replace_urls(in_string, replacement=None):\n",
    "#     # \"\"\"Replace URLs in strings. See also: ``bit.ly/PyURLre``\n",
    "\n",
    "#     # Args:\n",
    "#     #     in_string (str): string to filter\n",
    "#     #     replacement (str or None): replacment text. defaults to '<-URL->'\n",
    "\n",
    "#     # Returns:\n",
    "#     #     str\n",
    "#     # \"\"\"\n",
    "#     replacement = '<-URL->' if replacement is None else replacement\n",
    "#     pattern = re.compile('(https?://)?(\\w*[.]\\w+)+([/?=&]+\\w+)*')\n",
    "#     return re.sub(pattern, replacement, in_string)\n",
    "\n",
    "\n",
    "def tokenize_only(in_string):\n",
    "    \"\"\"\n",
    "    Convert `in_string` of text to a list of tokens using NLTK's TweetTokenizer\n",
    "    \"\"\"\n",
    "    # reasonable, but adjustable tokenizer settings\n",
    "    tokenizer = TweetTokenizer(preserve_case=False,\n",
    "                               reduce_len=True,\n",
    "                               strip_handles=False)\n",
    "    tokens = tokenizer.tokenize(in_string)\n",
    "    return tokens\n",
    "\n",
    "#remove punctuations -- this method is not in use\n",
    "# def rm_punctuation(tweet):\n",
    "#     RE_PUNCTUATION = '|'.join([re.escape(x) for x in string.punctuation])  \n",
    "#     print(f'this is the punctuation  {RE_PUNCTUATION}')\n",
    "#     print(\"\\n\")\n",
    "#     newValue = tweet.replace(RE_PUNCTUATION, \"\")\n",
    "#     return newValue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This step is done in Sentiment Analyzer\n",
    "# # remove urls and retweets and entities from the text\n",
    "# tweet_df_location['text_clean'] = tweet_df_location['text'].apply(lambda row:replace_urls(row))\n",
    "\n",
    "# #remove punctuations\n",
    "# RE_PUNCTUATION = '|'.join([re.escape(x) for x in string.punctuation])  \n",
    "# tweet_df_location['text_clean'] = tweet_df_location['text_clean'].str.replace(RE_PUNCTUATION, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' said', ' also', '#climatecrisis', 'too', ' are', \"i've\", ' about', ' did', 'weren', 'no', \" could've\", 'themselves', 'mightn', 'theirs', ' must', \" where'll\", \"wouldn't\", ' like', ' what', ' yet', ' us', 'now', 'off', 'yourselves', ' a', 'i', '#GreenNewDeal', \" must've\", \" wouldn't\", 'all', 'any', ' her', ' into', 'but', ' will', ' only', 'myself', ' own', ' cannot', 'with', \"he'd\", \"she'd\", 'my', ' my', ' does', ' an', ' could', \" he'd\", ' neither', \" shouldn't\", \" she's\", 'as', \" what's\", 'needn', ' let', '#bushfires', ' can', \"we're\", ' am', ' on', ' other', 'each', \" who'll\", 'whom', 'he', ' we', 'down', 'only', \"shan't\", ' them', ' than', 'same', ' dear', \" he'll\", ' may', 'where', ' of', \"couldn't\", 'y', ' able', 'm', 'll', ' some', 'until', ' but', \" we'll\", 'should', 'this', 'their', \"doesn't\", ' at', ' i', 'during', \" there's\", 'own', 'haven', ' all', 'for', ' ever', \"how's\", ' either', \"isn't\", 'am', 'against', \"won't\", 'very', 'if', \" why'll\", ' whom', 'so', ' this', 're', ' often', \" when'd\", 'above', ' most', \"aren't\", '#environment', ' from', ' should', 'some', ' every', \" would've\", ' wants', 'a', '#climatechange', 'had', 'about', 'doesn', 'were', 'we', 'mustn', '#climatestrike', 'has', '#savetheplanet', 'hers', \" what'd\", \" they'd\", 'herself', \"hasn't\", 'them', \" 'twas\", \" wasn't\", 'few', \" who's\", 's', ' as', ' likely', 'in', ' he', ' to', '#climateAction', \" where'd\", 'such', 'our', \"he'll\", \" i'm\", \"i'm\", 'yours', \"haven't\", \" how'd\", 'his', 'isn', \"here's\", ' do', \" won't\", \" mustn't\", 'from', '#GlobalWarming', 'between', ' say', \" how's\", \" it's\", \"you're\", 'below', ' it', 'who', 'you', ' there', 'been', 'through', 'those', ' who', \"weren't\", \" doesn't\", 'these', \" when'll\", 'being', \" couldn't\", ' else', 'didn', 'o', \" aren't\", \"i'd\", \" hasn't\", \" they'll\", ' any', 'out', ' why', ' off', 'at', ' then', \"we've\", ' least', 'me', \" he's\", \"let's\", 'that', \"they'll\", 'into', 've', 'wouldn', \"it's\", 'http', 'could', 'when', ' when', ' our', '#FridaysForFuture', \" she'd\", \" i'll\", ' with', 'nor', '#climateStrike', 'its', \"they'd\", ' might', 't', 'him', \" don't\", 'ain', 'which', ' not', 'wasn', \" you're\", 'just', 'himself', ' has', ' by', 'will', 'than', \" weren't\", \"didn't\", ' how', \" that's\", ' or', \" shan't\", ' in', ' after', \"i'll\", ' because', \"mightn't\", ' almost', \" mightn't\", 'won', \" might've\", \"that's\", ' its', 'again', ' these', \" ain't\", '#globalwarming', 'by', ' rather', 'was', 'there', \" where's\", 'she', 'ourselves', 'itself', 'd', 'are', \" didn't\", 'while', \" they've\", 'shouldn', \"we'd\", 'over', 'https', ' get', 'ought', 'how', \"mustn't\", 'couldn', \" they're\", ' his', \"where's\", \" i'd\", 'an', \"should've\", \" i've\", 'then', ' me', ' you', 'ma', \" she'll\", 'what', ' across', \" that'll\", 'both', \" should've\", \"when's\", 'can', \"who's\", ' for', 'further', ' among', 'before', 'to', \"you'll\", ' twas', 'hadn', 'shan', ' tis', 'most', ' which', ' nor', 'up', 'her', ' if', ' had', 'they', 'aren', \" isn't\", ' however', ' their', ' too', 'once', \"they've\", \" you'd\", ' the', ' since', 'your', \" how'll\", 'or', ' was', ' got', \"'tis\", \"we'll\", ' were', ' just', '#sustainability', 'here', \" we're\", 'does', \" when's\", \"there's\", ' and', ' where', 'having', ' she', ' him', 'be', 'more', \"what's\", ' while', '#bushfiresAustralia', 'and', ' would', 'it', \"that'll\", 'doing', \"you've\", 'of', ' that', \" you'll\", 'under', \"shouldn't\", \" we'd\", \"she's\", \"why's\", 'don', 'have', 'after', ' have', ' been', \" who'd\", \" why's\", \"wasn't\", 'the', ' says', \"don't\", ' they', 'yourself', \"needn't\", 'is', ' your', \"he's\", \"hadn't\", \" you've\", \"they're\", 'did', 'not', \"you'd\", 'ours', ' so', 'other', ' be', \" can't\", 'on', ' hers', ' no', ' is', 'do', \"she'll\", 'hasn', '#ActOnClimate', 'because', \" why'd\", 'why', 'would']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# List of stopwords\n",
    "stop_words= stopwords.words('english') #import stopwords from NLTK package\n",
    "readInStopwords = pd.read_csv(\"pre_process/twitterStopWords.csv\", encoding='ISO-8859-1') # import stopwords from CSV file as pandas data frame\n",
    "readInStopwords = readInStopwords.wordList.tolist() # convert pandas data frame to a list\n",
    "readInStopwords.append('http')\n",
    "readInStopwords.append('https')\n",
    "\n",
    "search_terms = ['#climateStrike','#climatestrike','#climatechange','#GreenNewDeal','#climatecrisis','#climateAction','#FridaysForFuture',\n",
    "            '#environment','#globalwarming','#GlobalWarming','#ActOnClimate','#sustainability','#savetheplanet',\n",
    "        '#bushfiresAustralia','#bushfires']\n",
    "readInStopwords.extend(search_terms)\n",
    "stop_list = stop_words + readInStopwords # combine two lists i.e. NLTK stop words and CSV stopwords\n",
    "stop_list = list(set(stop_list)) # strore only unique values \n",
    "    \n",
    "print(stop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tweet_df_location['text_clean']\n",
    "y = tweet_df_location['search_hashtags']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tasne\\envs\\newproject\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['#actonclimate', '#bushfiresaustralia', '#climateaction', '#fridaysforfuture', '#greennewdeal', \"'\", 'able', 'across', \"ain't\", 'almost', 'also', 'among', \"can't\", 'cannot', \"could've\", 'dear', 'either', 'else', 'ever', 'every', 'get', 'got', \"how'd\", \"how'll\", 'however', 'least', 'let', 'like', 'likely', 'may', 'might', \"might've\", 'must', \"must've\", 'neither', 'often', 'rather', 'said', 'say', 'says', 'since', 'tis', 'twas', 'us', 'wants', \"what'd\", \"when'd\", \"when'll\", \"where'd\", \"where'll\", \"who'd\", \"who'll\", \"why'd\", \"why'll\", \"would've\", 'yet'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# text_Vect = TfidfVectorizer()\n",
    "# X_Vect  = text_Vect.fit_transform(X)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "text_Vect = TfidfVectorizer(max_df=0.9, min_df=0.00, stop_words=stop_list, tokenizer=tokenize_only) # Use tf (raw term count) features for LDA.\n",
    "X_Vect = text_Vect.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_Vect, y, test_size=0.30, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50683, 87818)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50683,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21722, 87818)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21722,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LR(solver='sag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='sag', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 414    1   18   41   26   34    6    3    1   16    0    8]\n",
      " [   0  227    0   33    6    0    2    0    2    0    0    0]\n",
      " [   8    0 1256  217   59  255   19   23   24   26    3   23]\n",
      " [  26    5  212 3933  117  257   58   13  124   50   13   49]\n",
      " [  13    8   68  176 1015  121   14    8   25   39    2    6]\n",
      " [   6    4   66  121   30 5170   18   48   22   14    1    7]\n",
      " [   4    0   13   84    9   11 1185    0   25    3    7   70]\n",
      " [   2    4   32   30    9  329    5  486    4    4    3    3]\n",
      " [   0    0    5   83   20   34   17    2 1077    6    1    1]\n",
      " [  10    0   11   63   27   45    2    3    5 1200    4    7]\n",
      " [   0    0    3   12    5    9   23    1   12    0  349   16]\n",
      " [   3    0    9   47    7   11   48    0   21    3    5 1583]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    #actonclimate       0.85      0.73      0.79       568\n",
      "       #bushfires       0.91      0.84      0.87       270\n",
      "   #climateaction       0.74      0.66      0.70      1913\n",
      "   #climatechange       0.81      0.81      0.81      4857\n",
      "   #climatecrisis       0.76      0.68      0.72      1495\n",
      "   #climatestrike       0.82      0.94      0.88      5507\n",
      "     #environment       0.85      0.84      0.84      1411\n",
      "#fridaysforfuture       0.83      0.53      0.65       911\n",
      "   #globalwarming       0.80      0.86      0.83      1246\n",
      "    #greennewdeal       0.88      0.87      0.88      1377\n",
      "   #savetheplanet       0.90      0.81      0.85       430\n",
      "  #sustainability       0.89      0.91      0.90      1737\n",
      "\n",
      "         accuracy                           0.82     21722\n",
      "        macro avg       0.84      0.79      0.81     21722\n",
      "     weighted avg       0.82      0.82      0.82     21722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8238191695055704"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is --- \n",
    "- Accuracy is -- 0.8241414234416721 -- without tokens and stopwords\n",
    "- Accuracy is -- 0.8239112420587423 -- with tokenization and stopwords\n",
    "> Note adding tokens and stopwords does effect  accuracy a little bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 87818)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strVal =  [\"Cuyahoga county eliminates use of plastic bags\",\"Weather is still warm in winters and is not freezing\"]\n",
    "Value = text_Vect.transform(strVal)\n",
    "Value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['#environment', '#climatechange'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict(Value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation accuracy: 0.83\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "scores = cross_val_score(LogisticRegression(solver='saga'), X_train, y_train)\n",
    "print(\"Mean cross-validation accuracy: {:.2f}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.83\n",
      "Best parameters:  {'C': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1]}\n",
    "grid = GridSearchCV(LogisticRegression(solver='sag'), param_grid)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Best parameters: \", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Best cross-validation score: 0.83\n",
    "- Best parameters:  {'C': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['#environment', '#climatechange'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.predict(Value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
