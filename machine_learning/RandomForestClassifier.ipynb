{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df_location = pd.read_csv('../data/graphAnalysis/clean_climateTwitterData.csv')\n",
    "tweet_df_location = tweet_df_location[tweet_df_location['text'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "# This step already done in Sentiment Analyzer\n",
    "# def replace_urls(in_string, replacement=None):\n",
    "#     # \"\"\"Replace URLs in strings. See also: ``bit.ly/PyURLre``\n",
    "\n",
    "#     # Args:\n",
    "#     #     in_string (str): string to filter\n",
    "#     #     replacement (str or None): replacment text. defaults to '<-URL->'\n",
    "\n",
    "#     # Returns:\n",
    "#     #     str\n",
    "#     # \"\"\"\n",
    "#     replacement = '<-URL->' if replacement is None else replacement\n",
    "#     pattern = re.compile('(https?://)?(\\w*[.]\\w+)+([/?=&]+\\w+)*')\n",
    "#     return re.sub(pattern, replacement, in_string)\n",
    "\n",
    "\n",
    "def tokenize_only(in_string):\n",
    "    \"\"\"\n",
    "    Convert `in_string` of text to a list of tokens using NLTK's TweetTokenizer\n",
    "    \"\"\"\n",
    "    # reasonable, but adjustable tokenizer settings\n",
    "    tokenizer = TweetTokenizer(preserve_case=False,\n",
    "                               reduce_len=True,\n",
    "                               strip_handles=False)\n",
    "    tokens = tokenizer.tokenize(in_string)\n",
    "    return tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step already done in Sentiment Analyzer\n",
    "# # remove urls and retweets and entities from the text\n",
    "# tweet_df_location['text_clean'] = tweet_df_location['text'].apply(lambda row:replace_urls(row))\n",
    "\n",
    "# #remove punctuations\n",
    "# RE_PUNCTUATION = '|'.join([re.escape(x) for x in string.punctuation])  \n",
    "# tweet_df_location['text_clean'] = tweet_df_location['text_clean'].str.replace(RE_PUNCTUATION, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['be', \"he'll\", 'why', 'while', \" how'd\", \"should've\", ' on', 'the', ' often', '#sustainability', '#climatestrike', ' too', ' also', ' we', ' were', 'such', '#FridaysForFuture', 'themselves', \" doesn't\", \" 'twas\", \" aren't\", 'there', 'to', ' because', ' rather', 'doing', 'couldn', 'can', \"they'll\", 'we', \" how'll\", 'myself', \" they're\", \" why's\", 'it', \"that'll\", 'http', ' either', ' cannot', \" he'd\", \" ain't\", 'a', ' to', \" we'd\", \" couldn't\", 'will', \"haven't\", 'o', 'having', \" can't\", 'over', \" they'll\", ' hers', \"don't\", 'below', ' dear', ' ever', \"how's\", ' and', 'have', '#globalwarming', 'could', ' an', 'then', 'again', 'whom', 'doesn', \"we've\", ' your', ' across', 'y', 'd', \"they'd\", \" he's\", ' into', 'was', \"wasn't\", \"you're\", ' among', \"'tis\", 'so', 'm', \" why'd\", '#climatechange', \" would've\", 'out', 'under', \"why's\", ' said', \"they've\", '#environment', 'too', 'aren', 'what', 'your', 'with', 'theirs', 'that', 'as', 'she', 'ain', \" what's\", 'her', 'this', ' are', ' just', 't', 'all', ' own', ' neither', ' am', '#ActOnClimate', \"here's\", ' must', \" isn't\", ' us', \" hasn't\", 'during', ' me', 'how', '#GlobalWarming', \" wasn't\", \" he'll\", \" won't\", ' but', 'only', ' like', \"we'd\", \"let's\", \" you've\", 'down', ' nor', ' most', 'our', ' them', 'here', \" that'll\", ' least', 'into', 'each', ' in', 'not', \" shan't\", 'between', \"shan't\", 'nor', \" we're\", \"you'll\", 'own', 'more', 'ours', 'being', \" i'll\", 'of', \" you're\", ' says', ' as', ' was', 'because', 'is', 'does', \"mightn't\", 'before', 'me', \" we'll\", ' when', ' his', \"doesn't\", ' it', 'from', ' him', 'hadn', \"shouldn't\", \" shouldn't\", 'ourselves', 'needn', ' every', \" it's\", \" might've\", \" mustn't\", 'some', \"hadn't\", 'at', \" could've\", ' their', ' if', \"you've\", \" i've\", 'now', 'or', \" you'd\", ' could', ' then', \"mustn't\", 'any', \"wouldn't\", 'further', ' however', 'few', 'yours', ' they', 'himself', ' how', ' my', 's', 'are', 'when', 'same', \" that's\", 'were', 'mustn', ' got', \" weren't\", \" who's\", \"didn't\", 'against', 'am', ' have', ' some', 'other', 'off', 'which', 'no', \" what'd\", \" there's\", ' these', ' what', \" she'll\", \"who's\", \" she'd\", 'after', ' from', ' the', 'if', \"we'll\", ' else', ' by', \" why'll\", 'didn', ' can', \" i'd\", 'll', \"aren't\", 'once', \" where'll\", \" should've\", 'ought', ' which', 've', 'most', \" when'd\", 'do', 'just', ' why', ' any', 'until', ' only', 'they', 'where', ' would', ' did', \"she's\", \" wouldn't\", ' all', ' will', 'very', \" how's\", \"she'll\", ' of', \" must've\", \"needn't\", \" who'd\", \"she'd\", 'about', 'wouldn', 'through', \" when's\", ' with', \" where'd\", 'both', ' been', 'his', ' wants', '#climatecrisis', 'you', '#climateStrike', ' about', 're', ' does', ' should', 'those', 'its', '#bushfiresAustralia', ' had', ' than', '#GreenNewDeal', \"couldn't\", ' be', ' not', 'haven', '#climateAction', 'him', ' her', ' there', ' who', \" you'll\", ' no', 'wasn', \" i'm\", 'don', ' this', ' twas', ' do', \"we're\", 'an', 'won', ' able', \"what's\", ' at', \"he's\", ' other', ' so', 'https', 'yourselves', ' since', ' while', ' say', \"i'll\", 'had', \"you'd\", '#bushfires', ' a', 'has', ' is', \"they're\", ' he', 'in', \" didn't\", 'hers', 'but', 'been', ' our', 'did', \"i'd\", 'above', 'these', ' where', 'shouldn', \"that's\", 'hasn', 'who', \" she's\", ' might', 'them', \" who'll\", 'should', ' she', \"he'd\", ' after', \"where's\", ' likely', ' yet', ' its', 'he', 'than', 'ma', 'my', 'for', ' almost', 'herself', '#savetheplanet', \" where's\", \" they'd\", 'itself', \"hasn't\", \" they've\", \" don't\", 'their', 'isn', 'and', ' or', ' whom', ' get', \"isn't\", ' that', 'on', ' you', 'up', ' has', 'by', 'weren', ' tis', \"i'm\", ' let', \" when'll\", \"it's\", ' may', \"there's\", ' off', \"won't\", \"weren't\", 'yourself', 'mightn', \"when's\", 'i', \"i've\", ' for', 'shan', \" mightn't\", ' i', 'would']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# List of stopwords\n",
    "stop_words= stopwords.words('english') #import stopwords from NLTK package\n",
    "readInStopwords = pd.read_csv(\"pre_process/twitterStopWords.csv\", encoding='ISO-8859-1') # import stopwords from CSV file as pandas data frame\n",
    "readInStopwords = readInStopwords.wordList.tolist() # convert pandas data frame to a list\n",
    "readInStopwords.append('http')\n",
    "readInStopwords.append('https')\n",
    "\n",
    "search_terms = ['#climateStrike','#climatestrike','#climatechange','#GreenNewDeal','#climatecrisis','#climateAction','#FridaysForFuture',\n",
    "            '#environment','#globalwarming','#GlobalWarming','#ActOnClimate','#sustainability','#savetheplanet',\n",
    "        '#bushfiresAustralia','#bushfires']\n",
    "readInStopwords.extend(search_terms)\n",
    "stop_list = stop_words + readInStopwords # combine two lists i.e. NLTK stop words and CSV stopwords\n",
    "stop_list = list(set(stop_list)) # strore only unique values \n",
    "    \n",
    "print(stop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tweet_df_location['text_clean']\n",
    "y = tweet_df_location['search_hashtags']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tasne\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['#actonclimate', '#bushfiresaustralia', '#climateaction', '#fridaysforfuture', '#greennewdeal', \"'\", 'able', 'across', \"ain't\", 'almost', 'also', 'among', \"can't\", 'cannot', \"could've\", 'dear', 'either', 'else', 'ever', 'every', 'get', 'got', \"how'd\", \"how'll\", 'however', 'least', 'let', 'like', 'likely', 'may', 'might', \"might've\", 'must', \"must've\", 'neither', 'often', 'rather', 'said', 'say', 'says', 'since', 'tis', 'twas', 'us', 'wants', \"what'd\", \"when'd\", \"when'll\", \"where'd\", \"where'll\", \"who'd\", \"who'll\", \"why'd\", \"why'll\", \"would've\", 'yet'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf_vectorizer = TfidfVectorizer(max_df=0.9, min_df=0.00, stop_words=stop_list, tokenizer=tokenize_only) # Use tf (raw term count) features for LDA.\n",
    "X_Vect = tf_vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_Vect, y, test_size=0.30, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50683, 87818)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50683,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21722, 87818)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21722,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RFC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tasne\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 408    1   18   47   29   32    4    5    1   17    0    6]\n",
      " [   0  211    2   44    7    2    1    1    2    0    0    0]\n",
      " [  11    1 1260  192   63  247   23   39   24   29    4   20]\n",
      " [  36   26  264 3744  145  257   88   36  119   66   19   57]\n",
      " [  15   10   82  176 1003  117   12   15   21   35    3    6]\n",
      " [   7    2  164  201   87 4751   10  203   27   45    1    9]\n",
      " [   7    0   11   93   12   20 1153    3   25    3   11   73]\n",
      " [   4    2   38   27   12  349    3  457    7    5    2    5]\n",
      " [   1    2    9  103   30   38   22    0 1032    5    0    4]\n",
      " [  12    2   17   49   29   38    2    7    4 1204    7    6]\n",
      " [   0    0    4   18    5   12   20    3   15    0  341   12]\n",
      " [   2    0   16   67    9   14   57    6   18    3   11 1534]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    #actonclimate       0.81      0.72      0.76       568\n",
      "       #bushfires       0.82      0.78      0.80       270\n",
      "   #climateaction       0.67      0.66      0.66      1913\n",
      "   #climatechange       0.79      0.77      0.78      4857\n",
      "   #climatecrisis       0.70      0.67      0.69      1495\n",
      "   #climatestrike       0.81      0.86      0.83      5507\n",
      "     #environment       0.83      0.82      0.82      1411\n",
      "#fridaysforfuture       0.59      0.50      0.54       911\n",
      "   #globalwarming       0.80      0.83      0.81      1246\n",
      "    #greennewdeal       0.85      0.87      0.86      1377\n",
      "   #savetheplanet       0.85      0.79      0.82       430\n",
      "  #sustainability       0.89      0.88      0.88      1737\n",
      "\n",
      "         accuracy                           0.79     21722\n",
      "        macro avg       0.78      0.76      0.77     21722\n",
      "     weighted avg       0.79      0.79      0.79     21722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                           precision    recall  f1-score   support\n",
    "\n",
    "        #actonclimate       0.81      0.72      0.76       568\n",
    "           #bushfires       0.82      0.78      0.80       270\n",
    "       #climateaction       0.67      0.66      0.66      1913\n",
    "       #climatechange       0.79      0.77      0.78      4857\n",
    "       #climatecrisis       0.70      0.67      0.69      1495\n",
    "       #climatestrike       0.81      0.86      0.83      5507\n",
    "         #environment       0.83      0.82      0.82      1411\n",
    "    #fridaysforfuture       0.59      0.50      0.54       911\n",
    "       #globalwarming       0.80      0.83      0.81      1246\n",
    "        #greennewdeal       0.85      0.87      0.86      1377\n",
    "       #savetheplanet       0.85      0.79      0.82       430\n",
    "      #sustainability       0.89      0.88      0.88      1737\n",
    "\n",
    "             accuracy                           0.79     21722\n",
    "            macro avg       0.78      0.76      0.77     21722\n",
    "         weighted avg       0.79      0.79      0.79     21722"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7871282570665684"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy is -- 0.7970720928091336 without Tokenization and Stopwords\n",
    "- Accuracy is -- 0.7871282570665684 with Tokenization and Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 87818)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strVal = [\"People are getting aware of the surrounding \",\"things are super bad\"]\n",
    "Value = tf_vectorizer.transform(strVal)\n",
    "Value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['#climatestrike', '#climatechange'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.predict(Value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier model Train Acc: 0.893\n",
      "RandomForestClassifier model Test Acc: 0.787\n"
     ]
    }
   ],
   "source": [
    "print('RandomForestClassifier model Train Acc: %.3f' % rfc.score(X_train, y_train))\n",
    "print('RandomForestClassifier model Test Acc: %.3f' % rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'n_estimators': [200, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc1=RFC(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tasne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] max_depth=125, n_estimators=250 .................................\n",
      "[CV] ..... max_depth=125, n_estimators=250, score=0.816, total=22.2min\n",
      "[CV] max_depth=125, n_estimators=250 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 22.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... max_depth=125, n_estimators=250, score=0.813, total=26.2min\n",
      "[CV] max_depth=125, n_estimators=250 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 48.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... max_depth=125, n_estimators=250, score=0.818, total=25.6min\n",
      "[CV] max_depth=125, n_estimators=300 .................................\n",
      "[CV] ..... max_depth=125, n_estimators=300, score=0.815, total=29.8min\n",
      "[CV] max_depth=125, n_estimators=300 .................................\n",
      "[CV] ..... max_depth=125, n_estimators=300, score=0.814, total=29.9min\n",
      "[CV] max_depth=125, n_estimators=300 .................................\n",
      "[CV] ..... max_depth=125, n_estimators=300, score=0.817, total=33.7min\n",
      "[CV] max_depth=125, n_estimators=350 .................................\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid2 = {'n_estimators': [250, 300, 350],\n",
    "              'max_depth': [125, 150, 175]}\n",
    "grid = GridSearchCV(rfc1, param_grid2, verbose=3)\n",
    "\n",
    "# CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "# CV_rfc.fit(X_train, y_train)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Best parameters: \", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C:\\Users\\tasne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
    "  warnings.warn(CV_WARNING, FutureWarning)\n",
    "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
    "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
    "[CV] max_depth=125, n_estimators=250 .................................\n",
    "[CV] ..... max_depth=125, n_estimators=250, score=0.816, total=22.2min\n",
    "[CV] max_depth=125, n_estimators=250 .................................\n",
    "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 22.2min remaining:    0.0s\n",
    "[CV] ..... max_depth=125, n_estimators=250, score=0.813, total=26.2min\n",
    "[CV] max_depth=125, n_estimators=250 .................................\n",
    "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 48.4min remaining:    0.0s\n",
    "[CV] ..... max_depth=125, n_estimators=250, score=0.818, total=25.6min\n",
    "[CV] max_depth=125, n_estimators=300 .................................\n",
    "[CV] ..... max_depth=125, n_estimators=300, score=0.815, total=29.8min\n",
    "[CV] max_depth=125, n_estimators=300 .................................\n",
    "[CV] ..... max_depth=125, n_estimators=300, score=0.814, total=29.9min\n",
    "[CV] max_depth=125, n_estimators=300 .................................\n",
    "[CV] ..... max_depth=125, n_estimators=300, score=0.817, total=33.7min\n",
    "[CV] max_depth=125, n_estimators=350 ................................."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
