{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tasne\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.externals import joblib\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df_location = pd.read_csv('../data/graphAnalysis/clean_climateTwitterData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'id', 'author_id', 'text', 'retweets', 'permalink',\n",
       "       'date', 'formatted_date', 'favorites', 'mentions', 'hashtags', 'geo',\n",
       "       'urls', 'search_hashtags', 'location', 'text_clean',\n",
       "       'tb_sentiment_polarity', 'tb_sentiment_subjectivity',\n",
       "       'textBlob_sentiment', 'vader_compound', 'vader_pos', 'vader_neg',\n",
       "       'vader_neu', 'V_Sentiment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df_location.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function for Tokenization\n",
    "\n",
    "def tokenize_only(in_string):\n",
    "    \"\"\"\n",
    "    Convert `in_string` of text to a list of tokens using NLTK's TweetTokenizer\n",
    "    \"\"\"\n",
    "    # reasonable, but adjustable tokenizer settings\n",
    "    tokenizer = TweetTokenizer(preserve_case=False,\n",
    "                               reduce_len=True,\n",
    "                               strip_handles=False)\n",
    "    tokens = tokenizer.tokenize(in_string)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['when', 'his', ' least', ' because', 'we', 'above', 'who', '#bushfires', ' could', \" where's\", 'below', \" would've\", ' from', 'you', ' let', \"i've\", \" how'd\", ' this', 'himself', \" 'twas\", \" they've\", \" where'd\", \"needn't\", '#FridaysForFuture', 'would', ' in', ' into', 'other', \" shouldn't\", '#savetheplanet', 'both', 'own', ' might', ' should', \"hasn't\", \" where'll\", '#climatestrike', 'yourselves', \" he'll\", 'me', ' there', 'into', 'which', ' an', ' twas', 'whom', \"what's\", ' no', ' off', \"you'd\", 'that', 'because', 'your', 'my', ' they', \" i'll\", ' rather', 'could', ' often', 'nor', 'and', \"we'll\", ' what', 'shouldn', \" why'll\", \" you're\", \" who's\", \" what'd\", ' since', \" when'd\", ' may', ' across', ' when', ' to', \" it's\", \" you've\", \" mustn't\", 'in', ' me', ' then', 'again', 'with', 'mightn', ' we', \" you'd\", \" there's\", \"who's\", ' says', 'further', 'by', 'couldn', 'she', \" when'll\", \" who'd\", ' either', 'at', ' will', \"i'll\", ' get', \" how's\", 'ma', \" wasn't\", 'during', ' too', 'this', 'them', 'then', \" why's\", ' like', \"he'd\", ' nor', \"mustn't\", 'it', ' am', 'its', 'will', ' about', \" should've\", ' so', ' a', ' i', 'hasn', 'do', ' also', 're', 'out', 'wasn', 'doesn', \" we'd\", 'have', ' them', \" can't\", ' their', \"haven't\", 'for', 'be', 'once', \"shan't\", 'her', ' and', ' your', ' likely', 'was', \" she's\", \" that'll\", ' wants', \"you're\", \"she'd\", ' hers', 'until', 'wouldn', ' our', \" mightn't\", \" how'll\", 'up', 'before', \" they're\", \"shouldn't\", 'as', 'most', ' with', \"she's\", 'off', ' as', 'on', \" he'd\", ' can', 'were', \"where's\", ' just', ' my', \" i'd\", 'ours', ' for', 'https', \" you'll\", 'having', \"don't\", \" wouldn't\", 'm', 'doing', 'to', 'yourself', 'such', 'some', 'where', \"they're\", '#GreenNewDeal', ' ever', \"isn't\", \"we're\", 'don', ' not', ' its', ' every', \" she'll\", 'than', ' must', 'aren', ' other', \"here's\", ' only', \" i'm\", \"it's\", \"weren't\", ' however', \" didn't\", 'not', ' while', 'he', 'the', 'if', 'being', 'all', 'under', ' say', \"that's\", 'been', ' where', ' would', ' was', 'herself', \"couldn't\", ' any', 'themselves', 'an', 'after', 'very', 'more', \"she'll\", 'only', ' said', \"you'll\", 'each', ' us', \" when's\", ' some', '#climatechange', ' tis', 'haven', 'between', 'there', ' else', 'why', 'but', \"let's\", 'now', \"wasn't\", 'shan', ' these', 'just', ' neither', \"i'd\", \" i've\", 'our', \"why's\", 'are', 'myself', 't', ' is', ' than', 'didn', '#climateStrike', ' dear', 's', \"aren't\", 'ain', \" aren't\", 've', ' at', 'has', \" they'll\", '#climatecrisis', 'hadn', \"i'm\", \" hasn't\", 'does', ' that', \"mightn't\", \"won't\", ' were', 'through', ' after', \"they'd\", \"'tis\", \" she'd\", \" doesn't\", \"he's\", ' he', 'http', ' she', ' who', ' all', ' are', ' does', 'over', \"they'll\", ' had', 'they', 'can', 'hers', \" might've\", \" why'd\", \" shan't\", \" must've\", 'against', 'should', ' which', \"wouldn't\", 'so', ' has', 'theirs', ' you', ' his', 'is', 'same', 'isn', 'down', \" they'd\", \"hadn't\", 'yours', 'd', \" he's\", ' why', '#sustainability', '#bushfiresAustralia', ' do', 'from', \"how's\", \" we'll\", ' got', 'am', 'about', \"when's\", 'any', 'a', \"didn't\", ' did', \"that'll\", 'while', ' by', \" who'll\", 'll', 'of', 'too', 'mustn', ' or', \" couldn't\", 'ourselves', \" could've\", ' cannot', \"we'd\", 'ought', ' be', ' among', \"should've\", \" we're\", \"doesn't\", '#environment', ' on', 'weren', \" weren't\", ' been', 'i', ' her', \" isn't\", 'did', ' of', \"he'll\", \" don't\", ' but', 'how', 'those', \" what's\", \"there's\", 'these', 'few', 'their', '#ActOnClimate', 'o', ' own', 'needn', \" won't\", 'had', ' able', '#GlobalWarming', ' the', 'him', 'y', ' yet', \"you've\", \"we've\", ' it', 'what', 'itself', \" ain't\", \"they've\", '#climateAction', 'won', 'no', ' most', \" that's\", '#globalwarming', ' how', ' whom', ' him', ' have', 'here', ' almost', ' if', 'or']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# List of stopwords\n",
    "stop_words= stopwords.words('english') #import stopwords from NLTK package\n",
    "readInStopwords = pd.read_csv(\"pre_process/twitterStopWords.csv\", encoding='ISO-8859-1') # import stopwords from CSV file as pandas data frame\n",
    "readInStopwords = readInStopwords.wordList.tolist() # convert pandas data frame to a list\n",
    "\n",
    "readInStopwords.append('http')\n",
    "readInStopwords.append('https')\n",
    "\n",
    "search_terms = ['#climateStrike','#climatestrike','#climatechange','#GreenNewDeal','#climatecrisis','#climateAction','#FridaysForFuture',\n",
    "            '#environment','#globalwarming','#GlobalWarming','#ActOnClimate','#sustainability','#savetheplanet',\n",
    "        '#bushfiresAustralia','#bushfires']\n",
    "\n",
    "readInStopwords.extend(search_terms)\n",
    "stop_list = stop_words + readInStopwords # combine two lists i.e. NLTK stop words and CSV stopwords\n",
    "stop_list = list(set(stop_list)) # strore only unique values \n",
    "    \n",
    "print(stop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tweet_df_location['text_clean']\n",
    "y = tweet_df_location['search_hashtags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf_vectorizer = TfidfVectorizer(max_df=0.9, min_df=0.00, stop_words=stop_list, tokenizer=tokenize_only)\n",
    "\n",
    "#X_Vect = tf_vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('tfidf',TfidfVectorizer(max_df=0.9, min_df=0.00, stop_words=stop_list, tokenizer=tokenize_only)),\n",
    "    ('clf',LinearSVC(C=0.01))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tasne\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['#actonclimate', '#bushfiresaustralia', '#climateaction', '#fridaysforfuture', '#greennewdeal', \"'\", 'able', 'across', \"ain't\", 'almost', 'also', 'among', \"can't\", 'cannot', \"could've\", 'dear', 'either', 'else', 'ever', 'every', 'get', 'got', \"how'd\", \"how'll\", 'however', 'least', 'let', 'like', 'likely', 'may', 'might', \"might've\", 'must', \"must've\", 'neither', 'often', 'rather', 'said', 'say', 'says', 'since', 'tis', 'twas', 'us', 'wants', \"what'd\", \"when'd\", \"when'll\", \"where'd\", \"where'll\", \"who'd\", \"who'll\", \"why'd\", \"why'll\", \"would've\", 'yet'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=0.9, max_features=None,\n",
       "                                 min_df=0.0, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=['when', 'his', ' least',\n",
       "                                             ' because', 'we', 'above', 'who',\n",
       "                                             '#bus...\n",
       "                                 strip_accents=None, sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function tokenize_only at 0x0000016DACE91400>,\n",
       "                                 use_idf=True, vocabulary=None)),\n",
       "                ('clf',\n",
       "                 LinearSVC(C=0.01, class_weight=None, dual=True,\n",
       "                           fit_intercept=True, intercept_scaling=1,\n",
       "                           loss='squared_hinge', max_iter=1000,\n",
       "                           multi_class='ovr', penalty='l2', random_state=None,\n",
       "                           tol=0.0001, verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 399    1   11   55   28   28   13    1    1   21    0   10]\n",
      " [   0  207    0   55    3    0    2    0    3    0    0    0]\n",
      " [   8    0 1218  253   57  250   30    3   26   34    4   30]\n",
      " [   9    2   32 4356   18  217   28    2   94   39    3   57]\n",
      " [   6    8   24  193 1046  109   18    0   28   51    2   10]\n",
      " [   5    4   10   91   10 5294   23    7   19   23    4   17]\n",
      " [   0    0    5   96    3    8 1202    0   20    3    1   73]\n",
      " [   5    4   33   56    9  353   15  418    5    6    4    3]\n",
      " [   0    1    1  105    0   17   24    1 1079    5    0   13]\n",
      " [   0    0    3   56    0   44    1    1    5 1259    1    7]\n",
      " [   0    0    3   20    3   12   25    0   16    2  334   15]\n",
      " [   0    0    0   21    2    5   11    0   16    1    1 1680]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    #actonclimate       0.92      0.70      0.80       568\n",
      "       #bushfires       0.91      0.77      0.83       270\n",
      "   #climateaction       0.91      0.64      0.75      1913\n",
      "   #climatechange       0.81      0.90      0.85      4857\n",
      "   #climatecrisis       0.89      0.70      0.78      1495\n",
      "   #climatestrike       0.84      0.96      0.89      5507\n",
      "     #environment       0.86      0.85      0.86      1411\n",
      "#fridaysforfuture       0.97      0.46      0.62       911\n",
      "   #globalwarming       0.82      0.87      0.84      1246\n",
      "    #greennewdeal       0.87      0.91      0.89      1377\n",
      "   #savetheplanet       0.94      0.78      0.85       430\n",
      "  #sustainability       0.88      0.97      0.92      1737\n",
      "\n",
      "         accuracy                           0.85     21722\n",
      "        macro avg       0.89      0.79      0.82     21722\n",
      "     weighted avg       0.86      0.85      0.85     21722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                       precision    recall  f1-score   support\n",
    "\n",
    "        #actonclimate       0.92      0.70      0.80       568\n",
    "           #bushfires       0.91      0.77      0.83       270\n",
    "       #climateaction       0.91      0.64      0.75      1913\n",
    "       #climatechange       0.81      0.90      0.85      4857\n",
    "       #climatecrisis       0.89      0.70      0.78      1495\n",
    "       #climatestrike       0.84      0.96      0.89      5507\n",
    "       #environment         0.86      0.85      0.86      1411\n",
    "       #fridaysforfuture    0.97      0.46      0.62       911\n",
    "       #globalwarming       0.82      0.87      0.84      1246\n",
    "        #greennewdeal       0.87      0.91      0.89      1377\n",
    "       #savetheplanet       0.94      0.78      0.85       430\n",
    "      #sustainability       0.88      0.97      0.92      1737\n",
    "\n",
    "         accuracy                           0.85     21722\n",
    "        macro avg       0.89      0.79      0.82     21722\n",
    "     weighted avg       0.86      0.85      0.85     21722"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8513028266273823"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is --- 0.8101003590829574 \n",
    "Accuracy changed to point 0.85 after tuning the LinearSVC model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['twitterLinearSVCModel.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "joblib.dump(text_clf, 'twitterLinearSVCModel.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['#environment', '#climatechange', '#climatechange',\n",
       "       '#climatestrike'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.predict([\"Cuyahoga county eliminates use of plastic bags\",\n",
    "                  \"Weather is still warm in winters and is not freezing\",\n",
    "                  \"Actions are more important for a greater cause\",\n",
    "                  \"Its freezing out today may be need to drive my SUV more\"\n",
    "                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#climatechange'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.predict([\"Too much rain in moonsoon\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#climatestrike'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.predict([\"Schools strikes in sweden\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#climatechange'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.predict([\"buy a tesla save the earth\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tasne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\tasne\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['#actonclimate', '#bushfiresaustralia', '#climateaction', '#fridaysforfuture', '#greennewdeal', \"'\", 'able', 'across', \"ain't\", 'almost', 'also', 'among', \"can't\", 'cannot', \"could've\", 'dear', 'either', 'else', 'ever', 'every', 'get', 'got', \"how'd\", \"how'll\", 'however', 'least', 'let', 'like', 'likely', 'may', 'might', \"might've\", 'must', \"must've\", 'neither', 'often', 'rather', 'said', 'say', 'says', 'since', 'tis', 'twas', 'us', 'wants', \"what'd\", \"when'd\", \"when'll\", \"where'd\", \"where'll\", \"who'd\", \"who'll\", \"why'd\", \"why'll\", \"would've\", 'yet'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.86\n",
      "Best parameters:  {'clf__C': 0.01, 'tfidf__ngram_range': (1, 1), 'tfidf__use_idf': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters_svm = {'tfidf__ngram_range': [(1, 1), (1, 2)], 'tfidf__use_idf': (True, False),'clf__C': (0.001, 0.01, 0.1, 1)}\n",
    "gs_clf = GridSearchCV(text_clf, parameters_svm, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(X_train, y_train)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(gs_clf.best_score_))\n",
    "print(\"Best parameters: \", gs_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8491851579044287"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "# nltk.download()\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])\n",
    "    \n",
    "stemmed_count_vect = StemmedCountVectorizer(stop_words='english')\n",
    "\n",
    "text_mnb_stemmed = Pipeline([('vect', stemmed_count_vect), ('tfidf', TfidfTransformer()), \n",
    "                             ('svc', LinearSVC(C=0.01))])\n",
    "\n",
    "text_mnb_stemmed = text_mnb_stemmed.fit(X_train, y_train)\n",
    "\n",
    "predicted_mnb_stemmed = text_mnb_stemmed.predict(X_test)\n",
    "\n",
    "np.mean(predicted_mnb_stemmed == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tasne\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.86\n",
      "Best parameters:  {'svc__C': 0.01, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters_svm = {'vect__ngram_range': [(1, 1), (1, 2)], 'tfidf__use_idf': (True, False),'svc__C': (0.001, 0.01, 0.1, 1)}\n",
    "gs_clf1 = GridSearchCV(text_mnb_stemmed, parameters_svm, n_jobs=-1)\n",
    "gs_clf1 = gs_clf1.fit(X_train, y_train)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(gs_clf1.best_score_))\n",
    "print(\"Best parameters: \", gs_clf1.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
